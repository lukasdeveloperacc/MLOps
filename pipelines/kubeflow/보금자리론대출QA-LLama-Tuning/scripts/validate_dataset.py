#!/usr/bin/env python3
"""
SFT ë°ì´í„°ì…‹ í’ˆì§ˆ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

ê²€ì¦ í•­ëª©:
- LLaMA í† í° í¬ë§· ìœ íš¨ì„±
- UTF-8 ì¸ì½”ë”©
- ìµœì†Œ ë°ì´í„° ì„ê³„ê°’
- í•œêµ­ì–´ ë¹„ìœ¨
- ì¤‘ë³µ ê²€ì‚¬
- ë‹µë³€ ê¸¸ì´ í†µê³„
"""

import argparse
import json
import logging
import re
from collections import Counter
from pathlib import Path
from typing import List, Dict, Tuple


logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DatasetValidator:
    """SFT ë°ì´í„°ì…‹ ê²€ì¦ê¸°"""

    # LLaMA Instruct í† í° íŒ¨í„´
    LLAMA_PATTERN = re.compile(
        r'<s>\[INST\].*?\[/INST\].*?</s>',
        re.DOTALL
    )

    # í•œêµ­ì–´ ë¬¸ì íŒ¨í„´
    KOREAN_PATTERN = re.compile(r'[ê°€-í£]')

    def __init__(self):
        self.issues = []
        self.warnings = []
        self.stats = {
            'total_items': 0,
            'valid_format': 0,
            'invalid_format': 0,
            'duplicates': 0,
            'avg_answer_length': 0,
            'min_answer_length': float('inf'),
            'max_answer_length': 0,
            'avg_korean_ratio': 0
        }

    def load_dataset(self, path: Path) -> List[Dict[str, str]]:
        """JSONL ë°ì´í„°ì…‹ ë¡œë“œ

        Args:
            path: JSONL íŒŒì¼ ê²½ë¡œ

        Returns:
            ë°ì´í„°ì…‹ í•­ëª© ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"Loading dataset from {path}")

        items = []
        with open(path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                try:
                    item = json.loads(line.strip())
                    items.append(item)
                except json.JSONDecodeError as e:
                    self.issues.append(f"Line {line_num}: Invalid JSON - {e}")

        self.stats['total_items'] = len(items)
        logger.info(f"Loaded {len(items)} items")
        return items

    def validate_llama_format(self, text: str) -> bool:
        """LLaMA Instruct í¬ë§· ê²€ì¦

        Args:
            text: ê²€ì¦í•  í…ìŠ¤íŠ¸

        Returns:
            ìœ íš¨ ì—¬ë¶€
        """
        # í•„ìˆ˜ í† í° ì²´í¬
        required_tokens = ['<s>', '[INST]', '[/INST]', '</s>']
        for token in required_tokens:
            if token not in text:
                return False

        # ì „ì²´ íŒ¨í„´ ë§¤ì¹­
        if not self.LLAMA_PATTERN.search(text):
            return False

        return True

    def calculate_korean_ratio(self, text: str) -> float:
        """í•œêµ­ì–´ ë¹„ìœ¨ ê³„ì‚°

        Args:
            text: í…ìŠ¤íŠ¸

        Returns:
            í•œêµ­ì–´ ë¹„ìœ¨ (0.0 ~ 1.0)
        """
        if not text:
            return 0.0

        # ê³µë°± ì œì™¸í•œ ë¬¸ì ìˆ˜
        non_space_chars = len(text.replace(' ', '').replace('\n', ''))
        if non_space_chars == 0:
            return 0.0

        # í•œêµ­ì–´ ë¬¸ì ìˆ˜
        korean_chars = len(self.KOREAN_PATTERN.findall(text))

        return korean_chars / non_space_chars

    def extract_answer(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ë‹µë³€ ë¶€ë¶„ ì¶”ì¶œ

        Args:
            text: LLaMA Instruct í¬ë§· í…ìŠ¤íŠ¸

        Returns:
            ë‹µë³€ í…ìŠ¤íŠ¸
        """
        match = re.search(r'\[/INST\]\s*(.*?)\s*</s>', text, re.DOTALL)
        if match:
            return match.group(1).strip()
        return ""

    def validate_items(self, items: List[Dict[str, str]]) -> None:
        """ì „ì²´ í•­ëª© ê²€ì¦

        Args:
            items: ë°ì´í„°ì…‹ í•­ëª© ë¦¬ìŠ¤íŠ¸
        """
        seen_texts = set()
        answer_lengths = []
        korean_ratios = []

        for idx, item in enumerate(items, 1):
            text = item.get('text', '')

            # í¬ë§· ê²€ì¦
            if self.validate_llama_format(text):
                self.stats['valid_format'] += 1
            else:
                self.stats['invalid_format'] += 1
                self.issues.append(f"Item {idx}: Invalid LLaMA format")

            # ì¤‘ë³µ ì²´í¬
            if text in seen_texts:
                self.stats['duplicates'] += 1
                self.warnings.append(f"Item {idx}: Duplicate text")
            else:
                seen_texts.add(text)

            # ë‹µë³€ ê¸¸ì´ í†µê³„
            answer = self.extract_answer(text)
            answer_len = len(answer)
            answer_lengths.append(answer_len)

            self.stats['min_answer_length'] = min(
                self.stats['min_answer_length'],
                answer_len
            )
            self.stats['max_answer_length'] = max(
                self.stats['max_answer_length'],
                answer_len
            )

            # í•œêµ­ì–´ ë¹„ìœ¨
            korean_ratio = self.calculate_korean_ratio(text)
            korean_ratios.append(korean_ratio)

            # ë‚®ì€ í•œêµ­ì–´ ë¹„ìœ¨ ê²½ê³ 
            if korean_ratio < 0.5:
                self.warnings.append(
                    f"Item {idx}: Low Korean ratio ({korean_ratio:.2%})"
                )

            # ë„ˆë¬´ ì§§ì€ ë‹µë³€ ê²½ê³ 
            if answer_len < 10:
                self.warnings.append(
                    f"Item {idx}: Very short answer ({answer_len} chars)"
                )

        # í†µê³„ ê³„ì‚°
        if answer_lengths:
            self.stats['avg_answer_length'] = sum(answer_lengths) / len(answer_lengths)
        if korean_ratios:
            self.stats['avg_korean_ratio'] = sum(korean_ratios) / len(korean_ratios)

    def check_minimum_threshold(self, min_items: int = 50) -> None:
        """ìµœì†Œ ë°ì´í„° ì„ê³„ê°’ ì²´í¬

        Args:
            min_items: ìµœì†Œ í•­ëª© ìˆ˜
        """
        if self.stats['total_items'] < min_items:
            self.issues.append(
                f"Dataset has only {self.stats['total_items']} items "
                f"(minimum: {min_items})"
            )

    def check_korean_ratio_threshold(self, min_ratio: float = 0.7) -> None:
        """í•œêµ­ì–´ ë¹„ìœ¨ ì„ê³„ê°’ ì²´í¬

        Args:
            min_ratio: ìµœì†Œ í•œêµ­ì–´ ë¹„ìœ¨
        """
        if self.stats['avg_korean_ratio'] < min_ratio:
            self.issues.append(
                f"Average Korean ratio is {self.stats['avg_korean_ratio']:.2%} "
                f"(minimum: {min_ratio:.0%})"
            )

    def print_report(self) -> None:
        """ê²€ì¦ ë³´ê³ ì„œ ì¶œë ¥"""
        logger.info("\n" + "="*80)
        logger.info("VALIDATION REPORT")
        logger.info("="*80)

        # í†µê³„
        logger.info("\nğŸ“Š Statistics:")
        logger.info(f"  Total items: {self.stats['total_items']}")
        logger.info(f"  Valid format: {self.stats['valid_format']}")
        logger.info(f"  Invalid format: {self.stats['invalid_format']}")
        logger.info(f"  Duplicates: {self.stats['duplicates']}")
        logger.info(f"  Avg answer length: {self.stats['avg_answer_length']:.1f} chars")
        logger.info(f"  Min answer length: {self.stats['min_answer_length']} chars")
        logger.info(f"  Max answer length: {self.stats['max_answer_length']} chars")
        logger.info(f"  Avg Korean ratio: {self.stats['avg_korean_ratio']:.2%}")

        # ì´ìŠˆ
        if self.issues:
            logger.warning(f"\nâŒ Critical Issues ({len(self.issues)}):")
            for issue in self.issues[:10]:  # ìµœëŒ€ 10ê°œë§Œ ì¶œë ¥
                logger.warning(f"  - {issue}")
            if len(self.issues) > 10:
                logger.warning(f"  ... and {len(self.issues) - 10} more issues")
        else:
            logger.info("\nâœ… No critical issues found!")

        # ê²½ê³ 
        if self.warnings:
            logger.info(f"\nâš ï¸  Warnings ({len(self.warnings)}):")
            for warning in self.warnings[:10]:  # ìµœëŒ€ 10ê°œë§Œ ì¶œë ¥
                logger.info(f"  - {warning}")
            if len(self.warnings) > 10:
                logger.info(f"  ... and {len(self.warnings) - 10} more warnings")

        logger.info("\n" + "="*80)

    def is_valid(self) -> bool:
        """ê²€ì¦ í†µê³¼ ì—¬ë¶€

        Returns:
            Critical issueê°€ ì—†ìœ¼ë©´ True
        """
        return len(self.issues) == 0


def main():
    parser = argparse.ArgumentParser(description='SFT ë°ì´í„°ì…‹ í’ˆì§ˆ ê²€ì¦')
    parser.add_argument(
        '--input',
        type=Path,
        default=Path(__file__).parent.parent / 'data' / 'sft_dataset.jsonl',
        help='ì…ë ¥ JSONL íŒŒì¼ ê²½ë¡œ'
    )
    parser.add_argument(
        '--min-items',
        type=int,
        default=50,
        help='ìµœì†Œ í•­ëª© ìˆ˜'
    )
    parser.add_argument(
        '--min-korean-ratio',
        type=float,
        default=0.7,
        help='ìµœì†Œ í•œêµ­ì–´ ë¹„ìœ¨ (0.0 ~ 1.0)'
    )
    parser.add_argument(
        '--strict',
        action='store_true',
        help='ì—„ê²© ëª¨ë“œ (ê²½ê³ ë„ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬)'
    )

    args = parser.parse_args()

    # ì…ë ¥ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not args.input.exists():
        logger.error(f"Input file not found: {args.input}")
        return 1

    # ê²€ì¦ ì‹¤í–‰
    validator = DatasetValidator()

    items = validator.load_dataset(args.input)
    if not items:
        logger.error("No items to validate!")
        return 1

    validator.validate_items(items)
    validator.check_minimum_threshold(args.min_items)
    validator.check_korean_ratio_threshold(args.min_korean_ratio)

    # ë³´ê³ ì„œ ì¶œë ¥
    validator.print_report()

    # ê²°ê³¼ íŒì •
    if not validator.is_valid():
        logger.error("\nâŒ Validation FAILED!")
        return 1

    if args.strict and validator.warnings:
        logger.error(f"\nâŒ Validation FAILED (strict mode: {len(validator.warnings)} warnings)")
        return 1

    logger.info("\nâœ… Validation PASSED!")
    return 0


if __name__ == '__main__':
    exit(main())
